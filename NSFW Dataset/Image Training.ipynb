{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40429fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff37ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Configure which GPU(s) to use\n",
    "    tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "    # Enable memory growth for each GPU\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb092c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f00e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61eaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "path = \"dataset/train/\"\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "for classes in tqdm(os.listdir(path)):\n",
    "    class_ = path + classes\n",
    "    for images in os.listdir(class_):\n",
    "        try:\n",
    "            image_path = class_ + '/' + images\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image,(224,224))\n",
    "            image = np.expand_dims(image,axis=0)\n",
    "            features = model.predict(image)[0]\n",
    "            trainX.append(features)\n",
    "            trainY.append(class_.split('/')[-1])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/test/\"\n",
    "\n",
    "testX = []\n",
    "testY = []\n",
    "for classes in tqdm(os.listdir(path)):\n",
    "    class_ = path + classes\n",
    "    for images in os.listdir(class_):\n",
    "        try:\n",
    "            image_path = class_ + '/' + images\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image,(224,224))\n",
    "            image = np.expand_dims(image,axis=0)\n",
    "            features = model.predict(image)[0]\n",
    "            testX.append(features)\n",
    "            testY.append(class_.split('/')[-1])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffa907",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.array(testX)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "trainY = le.fit_transform(trainY)\n",
    "testY = le.fit_transform(testY)\n",
    "trainY = to_categorical(trainY, 6)\n",
    "testY = to_categorical(testY, 6)\n",
    "print(trainX.shape,testX.shape,trainY.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# Add the input layer\n",
    "model1.add(Dense(units=512, activation='relu', input_dim=2048))\n",
    "\n",
    "# Add more hidden layers\n",
    "model1.add(Dense(units=256, activation='relu'))\n",
    "model1.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model1.add(Dense(units=6, activation='softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67104bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 2\n",
    "multi_model = multi_gpu_model(model1, gpus=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2b065",
   "metadata": {},
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(trainY), trainY)\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])#, class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e820d09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_model.fit(trainX, trainY, epochs=30, validation_data = (testX,testY), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e661b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model.save(\"nfsw.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d48397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "mymodel = load_model(\"nfsw.h5\")\n",
    "classes = open(\"classes.txt\",'r').read().split('\\n')[:-1]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcaf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/validation/\"\n",
    "\n",
    "validY = []\n",
    "predY = []\n",
    "for class_path in tqdm(os.listdir(path)):\n",
    "    class_ = path + class_path\n",
    "    for images in os.listdir(class_):\n",
    "        try:\n",
    "            image_path = class_ + '/' + images\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image,(224,224))\n",
    "            image = np.expand_dims(image,axis=0)\n",
    "            features = model.predict(image)[0]\n",
    "            features = np.expand_dims(features,axis=0)\n",
    "            pred = mymodel.predict(features)[0]\n",
    "            name = classes[np.argmax(pred)]\n",
    "            predY.append(name)\n",
    "            validY.append(class_.split('/')[2])\n",
    "        except:\n",
    "            print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265eead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validY), len(predY), validY[0], predY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f45d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = validY\n",
    "predicted_labels = predY\n",
    "confusion_matrix = np.zeros((len(true_labels), len(true_labels)), dtype=np.int32)\n",
    "labels = classes\n",
    "\n",
    "for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "    row_idx = labels.index(true_label)\n",
    "    col_idx = labels.index(predicted_label)\n",
    "    confusion_matrix[row_idx, col_idx] += 1\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980301e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
