{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b11e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c458562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac29e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c575c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100011003.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100011004.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100011005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100011006.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ClipID  Boredom  Engagement  Confusion  Frustration\n",
       "0  1100011002.avi        0           2          0            0\n",
       "1  1100011003.avi        0           2          0            0\n",
       "2  1100011004.avi        0           3          0            0\n",
       "3  1100011005.avi        0           3          0            0\n",
       "4  1100011006.avi        0           3          0            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AllLabels.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86271aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8925\n"
     ]
    }
   ],
   "source": [
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518bc079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 8925/8925 [00:00<00:00, 189951.71it/s]\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "\n",
    "for n in tqdm(range(len(df.index))):\n",
    "    names.append(df['ClipID'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e16d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "image_shape = (160,120,3)\n",
    "base_model = InceptionV3(input_tensor=layers.Input(image_shape),weights='imagenet',include_top=False)\n",
    "\n",
    "#incept = Model(inputs=base_model.input,outputs=base_model.get_layer('avg_pool').output)\n",
    "incept = Model(inputs=base_model.input,outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3913d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height , img_width = 120, 160\n",
    "seq_len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ab1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    frames_list = []     \n",
    "    vidObj = cv2.VideoCapture(video_path)\n",
    "    count = 1 \n",
    "    \n",
    "    while count <= seq_len:          \n",
    "        success, image = vidObj.read() \n",
    "        if success:\n",
    "            image = cv2.resize(image, (img_height, img_width))\n",
    "            cv2.imwrite(\"image.jpg\",image)\n",
    "            image = np.expand_dims(image,axis=0)\n",
    "            image = preprocess_input(image)\n",
    "            features = incept.predict(image)[0]\n",
    "            frames_list.append(features)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(\"Defected frame\",video_path.split('/')[-1])\n",
    "            break\n",
    "            \n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b4183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/'\n",
    "# z1 = df[['Boredom']]\n",
    "# z2 = df[['Engagement']]\n",
    "# z3 = df[['Confusion']]\n",
    "# z4 = df[['Frustration']]\n",
    "z = df[['Boredom', 'Engagement', 'Confusion', 'Frustration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99c240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [03:33<00:00,  1.87s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [01:26<00:00,  2.10s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [01:16<00:00,  2.25s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 93/93 [03:59<00:00,  2.58s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [04:25<00:00,  3.36s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 142/142 [07:44<00:00,  3.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:35<00:00,  3.99s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [04:36<00:00,  3.68s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [07:04<00:00,  4.88s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:40<00:00,  5.08s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 89/89 [08:11<00:00,  5.52s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [08:24<00:00,  6.47s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [03:29<00:00,  6.75s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [08:45<00:00,  6.74s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [02:40<00:00,  5.52s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [07:02<00:00,  6.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [11:49<00:00,  6.33s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [03:33<00:00,  6.88s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:29<00:00,  6.39s/it]\n",
      " 12%|█████████▋                                                                       | 13/109 [01:37<10:56,  6.84s/it]"
     ]
    }
   ],
   "source": [
    "X,y = list(), list()\n",
    "   \n",
    "for folders in os.listdir(path):\n",
    "    folder = path + folders\n",
    "    for items in tqdm(os.listdir(folder)):\n",
    "        data = folder + '/' + items\n",
    "        for subfolders in os.listdir(data):\n",
    "            subfolder = data + '/' + subfolders\n",
    "            for m, name in enumerate(names):\n",
    "                if subfolder.split('/')[-1] == name:\n",
    "                    frames = frames_extraction(subfolder)\n",
    "                    X.append(frames)\n",
    "                    y.append(z.values[m]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeba07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448bb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input((2,2048))\n",
    "x = layers.LSTM(512, return_sequences=False)(input_)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x1 = layers.Dense(4, activation='softmax')(x)\n",
    "# x2 = layers.Dense(4, activation='softmax')(x)\n",
    "# x3 = layers.Dense(4, activation='softmax')(x)\n",
    "# x4 = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=x1)#[x1,x2,x3,x4])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea72c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "number_videos_per_bath = 1\n",
    "steps = 8925//number_videos_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a6759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"log/\" \n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model.fit(X,y,  epochs=200, batch_size = 256, validation_split = 0.35,callbacks=[tensorboard_callback],verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"classroom.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "clf = load_model(\"classroom.h5\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read() \n",
    "classes = ['Boredom','Engagement','Confusion','Frustration']\n",
    "values = [0,1,2,3]\n",
    "\n",
    "def predict(frame):\n",
    "    frames=[]\n",
    "    for i in range(0,1):\n",
    "        ret, frame = cap.read()\n",
    "        original = frame.copy()\n",
    "        image = cv2.resize(frame, (299, 299))\n",
    "        image = np.expand_dims(image,axis=0)\n",
    "        image = preprocess_input(image)\n",
    "        features = incept.predict(image)[0]\n",
    "        frames.append(features)\n",
    "    return frames\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read() \n",
    "    if frame is None:\n",
    "        break\n",
    "    frames = predict(frame)\n",
    "    frames = np.array(frames)    \n",
    "    new_feature = np.expand_dims(frames,axis=0)\n",
    "    pred=clf.predict(new_feature)\n",
    "    print(classes[0]  + \": \" + str(values[np.argmax(pred[0])]),classes[1]  + \": \" + str(values[np.argmax(pred[1])]),\n",
    "          classes[2]  + \": \" + str(values[np.argmax(pred[2])]),classes[3]  + \": \" + str(values[np.argmax(pred[3])]))\n",
    "    print(\" \")\n",
    "    print(\"...................\")\n",
    "    \n",
    "    cv2.imshow(\"output\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e14416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
