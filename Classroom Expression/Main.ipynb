{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import face_recognition\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c575c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AllLabels.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "for n in tqdm(range(len(df.index))):\n",
    "    names.append(df['ClipID'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = 'dataset/'\n",
    "X_tr=[]\n",
    "\n",
    "for folders in tqdm(os.listdir(path)):\n",
    "    folder = path + folders\n",
    "    for items in os.listdir(folder):\n",
    "        data = folder + '/' + items\n",
    "        for subfolders in os.listdir(data):\n",
    "            subfolder = data + '/' + subfolders\n",
    "            for m, name in enumerate(names):\n",
    "                if subfolder.split('/')[-1] == name:\n",
    "                    cap = cv2.VideoCapture(subfolder)\n",
    "                    count = 0\n",
    "                    frames = []                    \n",
    "                    while True:\n",
    "                        ret, frame = cap.read()\n",
    "                        count += 9\n",
    "                        if frame is None:\n",
    "                            break\n",
    "                        rgb_frame = frame[:, :, ::-1]\n",
    "                        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "                        try:\n",
    "                            for face_location in face_locations:\n",
    "                                (top, right, bottom, left) = face_location\n",
    "                                face = frame[top:bottom, left:right]\n",
    "                                frame = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                                lbp = local_binary_pattern(frame, 21, 3)  \n",
    "                                frames.append(lbp)\n",
    "                                if len(frames) > 3:\n",
    "                                    break\n",
    "                        except:\n",
    "                            continue\n",
    "                        cap.set(1,count)                    \n",
    "                    X_tr.append(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54868526",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.array(X_tr)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc059a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df[['Boredom', 'Engagement', 'Confusion', 'Frustration']]\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d319bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label.values[:len(data)]\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ffdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, random_state=40)\n",
    "print(trainX.shape,testX.shape, trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c458562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb988bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1024, activation='relu', input_shape=(300,1536)))\n",
    "model.add(Dense(512, kernel_initializer='glorot_normal', kernel_regularizer=l2(0.001), activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(32, kernel_initializer='glorot_normal', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(4, kernel_initializer='glorot_normal', kernel_regularizer=l2(0.001), activation='softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea72c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit(trainX, trainY, batch_size=1024, validation_data=(testX, testY),epochs = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"classroom.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "clf = load_model(\"classroom.h5\")\n",
    "\n",
    "#cap = cv2.VideoCapture(\"rtsp://admin:admin@123@192.168.1.125:554/\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read() \n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 8.0, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "def predict(frame):\n",
    "    frames=[]\n",
    "    for i in range(0,35):\n",
    "        ret, frame = cap.read()\n",
    "        original = frame.copy()\n",
    "        frame1=cv2.resize(frame,(480,640))\n",
    "        frames.append(frame1)\n",
    "    return frames\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read() \n",
    "    if frame is None:\n",
    "        break\n",
    "    frames = predict(frame)\n",
    "    frames = np.array(frames)\n",
    "    clip = preprocess_input(frames)\n",
    "    rgb_feature = feature_extractor.predict(clip)[0]\n",
    "    rgb_feature = np.array(rgb_feature)\n",
    "    rgb_feature = rgb_feature.reshape(8,512)\n",
    "    new_feature = np.expand_dims(rgb_feature,axis=0)\n",
    "    pred=clf.predict(new_feature)[0]\n",
    "    print(pred)\n",
    "#     if pred[0] > pred[1]:# and pred[0] > 0.5: #0.7 Robbery\n",
    "#         label = \"[] Anomoly : Shoplifting Detected!\"\n",
    "#         cv2.putText(frame,label ,(20,20), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255), 3)\n",
    "#     else:\n",
    "#         label = \"[] Status: Normal\"\n",
    "#         cv2.putText(frame,label,(20,20), cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,125,60), 3)\n",
    "#     out.write(frame)\n",
    "    cv2.imshow(\"output\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e14416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
