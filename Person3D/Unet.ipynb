{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f008ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"EHF/\"\n",
    "\n",
    "data = []\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.jpg'):\n",
    "        image_path = path + images\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image,(256,256))\n",
    "        data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply_data(ply_pat):\n",
    "    pcd = o3d.io.read_point_cloud(ply_path)\n",
    "    vertices = np.asarray(pcd.points)\n",
    "    min_coords = np.min(vertices, axis=0)\n",
    "    max_coords = np.max(vertices, axis=0)\n",
    "    normalized_vertices = (vertices - min_coords) / (max_coords - min_coords)\n",
    "    image_array = np.zeros((256, 256, 3), dtype=np.uint8)  # Adjust the image size as needed\n",
    "    for vertex in normalized_vertices:\n",
    "        x, y, z = vertex\n",
    "        image_x = int(x * (image_array.shape[1] - 1))\n",
    "        image_y = int((1 - y) * (image_array.shape[0] - 1))  # Reverse the y-coordinate\n",
    "        image_array[image_y, image_x, :] = 255 \n",
    "    image = Image.fromarray(image_array)\n",
    "    image.save(\"check.jpg\")\n",
    "    img = cv2.imread(\"check.jpg\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = []\n",
    "\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.ply'):\n",
    "        ply_path = path + images\n",
    "        ply_data = load_ply_data(ply_path)\n",
    "        meshes.append(ply_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)#, dtype=\"float32\") / 255.0\n",
    "meshes = np.array(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, meshes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8056f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, Concatenate, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape=(256,256,3)):\n",
    "    inputs = Input(input_shape)\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = Concatenate(axis=3)([drop4, up6])\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = Concatenate(axis=3)([conv3, up7])\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = Concatenate(axis=3)([conv2, up8])\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = Concatenate(axis=3)([conv1, up9])\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    conv9 = Conv2D(3, 1, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv9)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba09238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(data, meshes, batch_size=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee329767",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"3dcheck.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"1.jpg\")\n",
    "image = cv2.resize(image,(256,256))\n",
    "image1 = np.expand_dims(image,axis=0)\n",
    "pred = model.predict(image1)[0]\n",
    "cv2.imwrite(\"check.jpg\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54526a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
