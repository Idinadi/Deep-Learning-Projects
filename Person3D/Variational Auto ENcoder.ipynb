{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfffaff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696de1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 604/604 [00:02<00:00, 219.27it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"EHF/\"\n",
    "\n",
    "data = []\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.jpg'):\n",
    "        image_path = path + images\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image,(256,256))\n",
    "        data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320e1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply_data(ply_pat):\n",
    "    pcd = o3d.io.read_point_cloud(ply_path)\n",
    "    vertices = np.asarray(pcd.points)\n",
    "    min_coords = np.min(vertices, axis=0)\n",
    "    max_coords = np.max(vertices, axis=0)\n",
    "    normalized_vertices = (vertices - min_coords) / (max_coords - min_coords)\n",
    "    image_array = np.zeros((256, 256, 3), dtype=np.uint8)  # Adjust the image size as needed\n",
    "    for vertex in normalized_vertices:\n",
    "        x, y, z = vertex\n",
    "        image_x = int(x * (image_array.shape[1] - 1))\n",
    "        image_y = int((1 - y) * (image_array.shape[0] - 1))  # Reverse the y-coordinate\n",
    "        image_array[image_y, image_x, :] = 255 \n",
    "    image = Image.fromarray(image_array)\n",
    "    image.save(\"check.jpg\")\n",
    "    img = cv2.imread(\"check.jpg\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2bec82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 604/604 [00:04<00:00, 132.74it/s]\n"
     ]
    }
   ],
   "source": [
    "meshes = []\n",
    "\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.ply'):\n",
    "        ply_path = path + images\n",
    "        ply_data = load_ply_data(ply_path)\n",
    "        meshes.append(ply_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b869ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)#, dtype=\"float32\") / 255.0\n",
    "meshes = np.array(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67601f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 256, 256, 3), (100, 256, 256, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, meshes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8680f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3947718",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.Input(shape=(256, 256, 3))\n",
    "x = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Decoder network\n",
    "x = layers.Dense(64 * 64 * 32, activation='relu')(encoded)\n",
    "x = layers.Reshape((64, 64, 32))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
    "decoded = layers.Conv2DTranspose(3, 3, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder model\n",
    "model = tf.keras.Model(encoder_inputs, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0411e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 65536)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               33554944  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 131072)            67239936  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 128, 128, 64)     18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 256, 256, 32)     18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 256, 256, 3)      867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,221,123\n",
      "Trainable params: 101,221,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80f3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_lr(epoch, lr):\n",
    "    base_lr = 0.001\n",
    "    max_lr = 0.01\n",
    "    step_size = 5\n",
    "    cycle = tf.floor(1 + epoch / (2 * step_size))\n",
    "    x = tf.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    new_lr = base_lr + (max_lr - base_lr) * tf.maximum(0, (1 - x))\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91df93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)\n",
    "lr_scheduler = LearningRateScheduler(cyclic_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f4e0717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 11s 904ms/step - loss: 5273.7393 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 5261.2183 - lr: 0.0028\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 2s 475ms/step - loss: 5260.2739 - lr: 0.0046\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 5260.2729 - lr: 0.0064\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 5260.2744 - lr: 0.0082\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 2s 475ms/step - loss: 5260.2739 - lr: 0.0100\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 5260.2744 - lr: 0.0082\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 5260.2739 - lr: 0.0064\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 5260.2739 - lr: 0.0046\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 5260.2739 - lr: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x234c876fca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=opt, loss='mse')\n",
    "model.fit(data, meshes, batch_size=32, epochs=10, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7eccd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"3dcheck.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0e6d6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"1.jpg\")\n",
    "image = cv2.resize(image,(256,256))\n",
    "image1 = np.expand_dims(image,axis=0)\n",
    "pred = model.predict(image1)[0]\n",
    "cv2.imwrite(\"output.jpg\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e3812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
