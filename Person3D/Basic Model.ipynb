{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b217f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7bfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"EHF/\"\n",
    "\n",
    "data = []\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.jpg'):\n",
    "        image_path = path + images\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image,(256,256))\n",
    "        data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76617506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply_data(ply_file_path):\n",
    "    mesh = trimesh.load_mesh(ply_file_path)\n",
    "    return mesh.vertices, mesh.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf53b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_data = []\n",
    "vertices_data = []\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.ply'):\n",
    "        ply_path = path + images\n",
    "        vertices, faces = load_ply_data(ply_path)\n",
    "        faces_data.append(faces)\n",
    "        vertices_data.append(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424bc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "faces_data = np.array(faces_data)\n",
    "vertices_data = np.array(vertices_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed569480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148594ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vertices = 10475\n",
    "num_faces = 20908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_output = vgg16.layers[-1].output\n",
    "\n",
    "conv1 = Conv2D(64, kernel_size=(3, 3), activation='relu')(vgg_output)\n",
    "conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(conv1)\n",
    "flatten = Flatten()(conv2)\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "\n",
    "reshape_vertices = Dense(num_vertices * 3, activation='linear')(dense1)\n",
    "reshape_faces = Dense(num_faces * 3, activation='linear')(dense1)\n",
    "\n",
    "reshape_vertices = Reshape((num_vertices, 3))(reshape_vertices)\n",
    "reshape_faces = Reshape((num_faces, 3))(reshape_faces)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=vgg16.input, outputs=[reshape_vertices, reshape_faces])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ae132",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67442368",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data, [vertices_data, faces_data], batch_size=2, epochs=983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefe207",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"3dcheck.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"3dcheck.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4cc492",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"1.jpg\")\n",
    "image = cv2.resize(image,(256,256))\n",
    "image1 = np.expand_dims(image,axis=0)\n",
    "predictions = model.predict(image1)\n",
    "print(predictions[0].shape, predictions[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2899fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vertices = predictions[0].squeeze(axis=0)\n",
    "predicted_faces = predictions[1].squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vertices = np.reshape(predicted_vertices, (-1, 3))\n",
    "predicted_faces = np.reshape(predicted_faces, (-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f115ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vertices.shape, predicted_faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and adjust the vertex indices in the faces array\n",
    "#max_vertex_index = predicted_vertices.shape[0] - 1\n",
    "#predicted_faces = np.where(predicted_faces > max_vertex_index, max_vertex_index, predicted_faces)\n",
    "\n",
    "# Create a trimesh object using the predicted vertices and faces\n",
    "mesh = trimesh.Trimesh(vertices=predicted_vertices, faces=predicted_faces)\n",
    "\n",
    "# Save the mesh as a .ply file\n",
    "output_file = \"predicted_mesh.ply\"\n",
    "mesh.export(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2123ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60037ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
