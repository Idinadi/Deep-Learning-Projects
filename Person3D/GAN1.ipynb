{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aaefa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os,cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"EHF/\"\n",
    "\n",
    "data = []\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.jpg'):\n",
    "        image_path = path + images\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image,(256,256))\n",
    "        data.append(image)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0381ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply_data(ply_pat):\n",
    "    pcd = o3d.io.read_point_cloud(ply_path)\n",
    "    vertices = np.asarray(pcd.points)\n",
    "    min_coords = np.min(vertices, axis=0)\n",
    "    max_coords = np.max(vertices, axis=0)\n",
    "    normalized_vertices = (vertices - min_coords) / (max_coords - min_coords)\n",
    "    image_array = np.zeros((256, 256, 3), dtype=np.uint8)  # Adjust the image size as needed\n",
    "    for vertex in normalized_vertices:\n",
    "        x, y, z = vertex\n",
    "        image_x = int(x * (image_array.shape[1] - 1))\n",
    "        image_y = int((1 - y) * (image_array.shape[0] - 1))  # Reverse the y-coordinate\n",
    "        image_array[image_y, image_x, :] = 255 \n",
    "    image = Image.fromarray(image_array)\n",
    "    image.save(\"check.jpg\")\n",
    "    img = cv2.imread(\"check.jpg\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3302d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = []\n",
    "\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.ply'):\n",
    "        ply_path = path + images\n",
    "        ply_data = load_ply_data(ply_path)\n",
    "        meshes.append(ply_data)\n",
    "meshes = np.array(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(meshes[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7663d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, meshes))\n",
    "dataset = dataset.batch(batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, LeakyReLU,Concatenate,Flatten,Dense,BatchNormalization,AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fbdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.scale = self.add_weight(name='scale',\n",
    "                                     shape=input_shape[-1:],\n",
    "                                     initializer=tf.random_normal_initializer(1., 0.02),\n",
    "                                     trainable=True)\n",
    "        self.offset = self.add_weight(name='offset',\n",
    "                                      shape=input_shape[-1:],\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(InstanceNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, var = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        inv = tf.math.rsqrt(var + 1e-5)\n",
    "        normalized = (x - mean) * inv\n",
    "        return self.scale * normalized + self.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a855454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    inputs = Input(shape=(256, 256,3))\n",
    "    \n",
    "    xi_and_y_i = inputs\n",
    "    xi_yi_sz64 = AveragePooling2D(pool_size=2)(xi_and_y_i)\n",
    "    xi_yi_sz32 = AveragePooling2D(pool_size=4)(xi_and_y_i)\n",
    "    xi_yi_sz16 = AveragePooling2D(pool_size=8)(xi_and_y_i)\n",
    "    xi_yi_sz8 = AveragePooling2D(pool_size=16)(xi_and_y_i)\n",
    "    layer1 = Conv2D(64, kernel_size=4, strides=2, \n",
    "                   padding=\"same\", name = 'layer1') (inputs)\n",
    "    layer1 = LeakyReLU(alpha=0.2)(layer1)\n",
    "    layer1 = concatenate([layer1, xi_yi_sz64]) # ==========\n",
    "    layer2 = Conv2D(128, kernel_size=4, strides=2, \n",
    "                   padding=\"same\", name = 'layer2') (layer1)\n",
    "    layer2 = InstanceNormalization()(layer2, training=1)\n",
    "    layer3 = LeakyReLU(alpha=0.2)(layer2)\n",
    "    layer3 = concatenate([layer3, xi_yi_sz32]) # ==========\n",
    "    layer3 = Conv2D(256, kernel_size=4, strides=2, \n",
    "                   padding=\"same\", name = 'layer3') (layer3)\n",
    "    \n",
    "    layer3 = InstanceNormalization()(layer3, training=1)\n",
    "    layer4 = LeakyReLU(alpha=0.2)(layer3)\n",
    "    layer4 = concatenate([layer4, xi_yi_sz16]) # ==========\n",
    "    layer4 = Conv2D(512, kernel_size=4, strides=2, \n",
    "                   padding=\"same\", name = 'layer4') (layer4)\n",
    "    \n",
    "    layer4 = InstanceNormalization()(layer4, training=1)\n",
    "    layer4 = LeakyReLU(alpha=0.2)(layer4)\n",
    "    layer4 = concatenate([layer4, xi_yi_sz8]) # ==========\n",
    "    \n",
    "    layer9 = Conv2DTranspose(256, kernel_size=4, strides=2, \n",
    "                            kernel_initializer = tf.keras.initializers.GlorotNormal(seed=None), name = 'layer9')(layer4) \n",
    "    layer9 = Cropping2D(((1,1),(1,1)))(layer9)\n",
    "    layer9 = InstanceNormalization()(layer9, training=1)\n",
    "    layer9 = Concatenate(axis=-1)([layer9, layer3])\n",
    "    layer9 = Activation('relu')(layer9)\n",
    "    layer9 = concatenate([layer9, xi_yi_sz16]) # ==========\n",
    "    layer10 = Conv2DTranspose(128, kernel_size=4, strides=2, \n",
    "                            kernel_initializer = tf.keras.initializers.GlorotNormal(seed=None), name = 'layer10')(layer9) \n",
    "    layer10 = Cropping2D(((1,1),(1,1)))(layer10)\n",
    "    \n",
    "    layer10 = InstanceNormalization()(layer10, training=1)\n",
    "    layer10 = Concatenate(axis=-1)([layer10, layer2])\n",
    "    layer10 = Activation('relu')(layer10)\n",
    "    layer10 = concatenate([layer10, xi_yi_sz32]) # ==========\n",
    "    layer11 = Conv2DTranspose(64, kernel_size=4, strides=2, \n",
    "                            kernel_initializer = tf.keras.initializers.GlorotNormal(seed=None), name = 'layer11')(layer10) \n",
    "    layer11 = Cropping2D(((1,1),(1,1)))(layer11)\n",
    "    \n",
    "    layer11 = InstanceNormalization()(layer11, training=1)\n",
    "    layer11 = Activation('relu')(layer11)\n",
    "        \n",
    "    layer12 = concatenate([layer11, xi_yi_sz64]) # ==========\n",
    "    layer12 = Activation('relu')(layer12)\n",
    "    layer12 = Conv2DTranspose(32, kernel_size=4, strides=2, \n",
    "                            kernel_initializer = tf.keras.initializers.GlorotNormal(seed=None), name = 'layer12')(layer12) \n",
    "    layer12 = Cropping2D(((1,1),(1,1)))(layer12)\n",
    "    \n",
    "    layer12 = InstanceNormalization()(layer12, training=1)\n",
    "    \n",
    "    layer12 = Conv2D(3, kernel_size=4, strides=1, \n",
    "                   padding=\"same\", name = 'out128') (layer12)\n",
    "    \n",
    "\n",
    "    alpha = Activation(\"sigmoid\", name='alpha_sigmoid')(layer12)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=alpha) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d003f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    input_shape =(256, 256, 3)\n",
    "    conv_base = tf.keras.applications.vgg16.VGG16(weights=None, include_top=False, input_shape=input_shape)\n",
    "    model_output = conv_base.output\n",
    "    x = Flatten()(model_output)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model(conv_base.input, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607232f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the models\n",
    "generator.compile(loss='mae', optimizer=generator_optimizer)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0099474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_output_fake, gen_output, target_image):\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target_image - gen_output))\n",
    "    adversarial_loss = tf.reduce_mean(tf.square(disc_output_fake - 1))\n",
    "    total_loss = l1_loss + (0.01 * adversarial_loss)\n",
    "    return total_loss\n",
    "\n",
    "def discriminator_loss(real_output, generated_output):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n",
    "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(generated_output), generated_output)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(dataset):\n",
    "    person_image, target_image = dataset\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        person_image = tf.cast(person_image, tf.float32)\n",
    "        target_image = tf.cast(target_image, tf.float32)\n",
    "\n",
    "        gen_inputs = person_image\n",
    "        gen_output = generator(gen_inputs, training=True)\n",
    "        # Concatenate input and target images for discriminator\n",
    "        disc_input_real = person_image\n",
    "        disc_input_fake = gen_output\n",
    "        disc_output_real = discriminator(disc_input_real, training=True)\n",
    "        disc_output_fake = discriminator(disc_input_fake, training=True)\n",
    "        # Calculate losses\n",
    "        gen_loss = generator_loss(disc_output_fake, gen_output, target_image)\n",
    "        disc_loss = discriminator_loss(disc_output_real, disc_output_fake)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "    return {'gen_loss': gen_loss, 'disc_loss': disc_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=1000\n",
    "gen_loss_avg = tf.keras.metrics.Mean('gen_loss', dtype=tf.float32)\n",
    "disc_loss_avg = tf.keras.metrics.Mean('disc_loss', dtype=tf.float32)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Running Epoch : {epoch+1}\")\n",
    "    for step, image_batch in enumerate(dataset):\n",
    "        results = train_step(image_batch)\n",
    "        gen_loss = results['gen_loss']\n",
    "        disc_loss = results['disc_loss']\n",
    "        # update the running averages for gen_loss and disc_loss\n",
    "        gen_loss_avg.update_state(gen_loss)\n",
    "        disc_loss_avg.update_state(disc_loss)\n",
    "        if (step + 1) % 10 == 0:\n",
    "            print('Epoch {}, Step {}, Gen Loss: {:.4f}, Disc Loss: {:.4f}'.format(epoch + 1, step + 1, gen_loss_avg.result(), disc_loss_avg.result()))\n",
    "    # reset the running averages at the end of each epoch\n",
    "    gen_loss_avg.reset_states()\n",
    "    disc_loss_avg.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49276a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(\"generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the person and shirt images\n",
    "person_image = Image.open('1.jpg')\n",
    "\n",
    "def predict(person_image, generator):\n",
    "    # Resize person and cloth images to match generator input size\n",
    "    person_image = tf.image.resize(person_image, [256, 256])\n",
    "\n",
    "    # Normalize person and cloth images to [0, 1] range\n",
    "    person_image = person_image / 255.0\n",
    "    person_image = np.expand_dims(person_image, axis=0)\n",
    "\n",
    "    output_image = generator(person_image, training=False)\n",
    "    # Denormalize output image and clip values to [0, 255] range\n",
    "    output_image = (output_image + 1) * 127.5\n",
    "    output_image = tf.clip_by_value(output_image, 0, 255)\n",
    "    # Convert output image to numpy array and return\n",
    "    output_image = output_image.numpy().astype(np.uint8)\n",
    "    return output_image\n",
    "\n",
    "\n",
    "output_image = predict(person_image, generator)\n",
    "output_image = output_image.squeeze()\n",
    "plt.imshow(output_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2e687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d03a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b1982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd949f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
