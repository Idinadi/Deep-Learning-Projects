{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58901a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69133e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 604/604 [00:02<00:00, 239.97it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"EHF/\"\n",
    "\n",
    "data = []\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.jpg'):\n",
    "        image_path = path + images\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image,(256,256))\n",
    "        data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee64057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply_data(ply_pat):\n",
    "    pcd = o3d.io.read_point_cloud(ply_path)\n",
    "    vertices = np.asarray(pcd.points)\n",
    "    min_coords = np.min(vertices, axis=0)\n",
    "    max_coords = np.max(vertices, axis=0)\n",
    "    normalized_vertices = (vertices - min_coords) / (max_coords - min_coords)\n",
    "    image_array = np.zeros((256, 256, 3), dtype=np.uint8)  # Adjust the image size as needed\n",
    "    for vertex in normalized_vertices:\n",
    "        x, y, z = vertex\n",
    "        image_x = int(x * (image_array.shape[1] - 1))\n",
    "        image_y = int((1 - y) * (image_array.shape[0] - 1))  # Reverse the y-coordinate\n",
    "        image_array[image_y, image_x, :] = 255 \n",
    "    image = Image.fromarray(image_array)\n",
    "    image.save(\"check.jpg\")\n",
    "    img = cv2.imread(\"check.jpg\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1daf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 604/604 [00:04<00:00, 140.95it/s]\n"
     ]
    }
   ],
   "source": [
    "meshes = []\n",
    "\n",
    "for images in tqdm(os.listdir(path)):\n",
    "    if images.endswith('.ply'):\n",
    "        ply_path = path + images\n",
    "        ply_data = load_ply_data(ply_path)\n",
    "        meshes.append(ply_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f408ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)#, dtype=\"float32\") / 255.0\n",
    "meshes = np.array(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcf5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, LeakyReLU,Concatenate,Flatten,Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c002a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator model\n",
    "def build_generator():\n",
    "    input_shape =(256,256, 3)\n",
    "    num_filters = 32\n",
    "\n",
    "    # Define the input layers\n",
    "    input_image = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    enc1 = Conv2D(num_filters, kernel_size=4, strides=2, padding='same', activation='relu')(input_image)\n",
    "    enc2 = Conv2D(num_filters*2, kernel_size=4, strides=2, padding='same', activation='relu')(enc1)\n",
    "    enc3 = Conv2D(num_filters*2, kernel_size=4, strides=2, padding='same', activation='relu')(enc2)\n",
    "    enc4 = Conv2D(num_filters*4, kernel_size=4, strides=2, padding='same', activation='relu')(enc3)\n",
    "    # Decoder\n",
    "    dec4 = Conv2DTranspose(num_filters*4, kernel_size=4, strides=2, padding='same', activation='relu')(enc4)\n",
    "    dec4 = concatenate([dec4, enc3], axis=-1)\n",
    "    dec5 = Conv2DTranspose(num_filters*2, kernel_size=4, strides=2, padding='same', activation='relu')(dec4)\n",
    "    dec5 = concatenate([dec5, enc2], axis=-1)\n",
    "    dec6 = Conv2DTranspose(num_filters*2, kernel_size=4, strides=2, padding='same', activation='relu')(dec5)\n",
    "    #dec6 = concatenate([dec6, enc1], axis=-1)\n",
    "    #dec7 = Conv2DTranspose(num_filters, kernel_size=4, strides=2, padding='same', activation='relu')(dec6)\n",
    "\n",
    "    # Output\n",
    "    output_image = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh')(dec6)\n",
    "\n",
    "    # Define the model inputs and outputs\n",
    "    generator_inputs = input_image\n",
    "    generator_outputs = output_image\n",
    "    model = tf.keras.Model(generator_inputs, generator_outputs, name='generator')\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f571c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    input_shape = (256, 256, 3)\n",
    "    input_a = Input(shape=input_shape)\n",
    "\n",
    "    d = Conv2D(64, 4, strides=2, padding='same')(input_a)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "    d = Conv2D(128, 4, strides=2, padding='same')(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "    d = Conv2D(256, 4, strides=2, padding='same')(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Flatten()(d)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(d)\n",
    "    model = Model(inputs=input_a, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "246a5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ef0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e5834c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adgan_input_image = Input(shape=(256, 256, 3))\n",
    "adgan_input_mask = Input(shape=(256, 256, 3))\n",
    "generated_image = generator(adgan_input_image)\n",
    "discriminator.trainable = False\n",
    "validity = discriminator([adgan_input_image, generated_image])\n",
    "adgan = Model(inputs=adgan_input_image, outputs=validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0a38705",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.compile(loss='mae', optimizer=generator_optimizer)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4bb6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generate_outputs(image, mask):\n",
    "    # Generate image using generator\n",
    "    generated_image = generator([image, mask], training=False)\n",
    "    # Evaluate discriminator outputs\n",
    "    disc_real_output = discriminator([image, mask], training=False)\n",
    "    disc_generated_output = discriminator([image, generated_image], training=False)\n",
    "    return disc_generated_output, generated_image, disc_real_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87eeacc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__generate_outputs() missing 1 required positional argument: 'mask'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(mask,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m disc_gen_output, gen_image, disc_real_output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m disc_gen_outputs\u001b[38;5;241m.\u001b[39mappend(disc_gen_output)\n\u001b[0;32m      9\u001b[0m gen_images\u001b[38;5;241m.\u001b[39mappend(gen_image)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__generate_outputs() missing 1 required positional argument: 'mask'\n"
     ]
    }
   ],
   "source": [
    "disc_gen_outputs, gen_images, disc_real_outputs = [], [], []\n",
    "target=[]\n",
    "\n",
    "for image, mask in zip(data, meshes):\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    mask = np.expand_dims(mask,axis=0)\n",
    "    disc_gen_output, gen_image, disc_real_output = generate_outputs(image)\n",
    "    disc_gen_outputs.append(disc_gen_output)\n",
    "    gen_images.append(gen_image)\n",
    "    disc_real_outputs.append(disc_real_output)\n",
    "    target.append(image)\n",
    "    \n",
    "# Define your loss functions\n",
    "def generator_loss(disc_gen_outputs, gen_images, target):\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    return l1_loss\n",
    "\n",
    "def discriminator_loss(real_output=disc_real_outputs, generated_output=disc_gen_outputs):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n",
    "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(generated_output), generated_output)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss\n",
    "\n",
    "adgan.compile(optimizer=generator_optimizer, loss=generator_loss, metrics=['mae', 'accuracy'])\n",
    "adgan.fit(data,meshes, epochs=100)\n",
    "\n",
    "tf.keras.models.save_model(generator, 'generator.h5')\n",
    "tf.keras.models.save_model(discriminator, 'discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6175a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
