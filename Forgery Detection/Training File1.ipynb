{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import AutoFeatureExtractor,TFViTMAEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model = AutoFeatureExtractor.from_pretrained(\"facebook/vit-mae-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"comofod/\"\n",
    "data = []\n",
    "labels = []\n",
    "for folders in os.listdir(path):\n",
    "    folder = path + folders\n",
    "    print(folder)\n",
    "    for items in tqdm(os.listdir(folder)):\n",
    "        item = folder + '/' + items\n",
    "        try:\n",
    "            image = cv2.resize(cv2.imread(item),(128,128))       \n",
    "            #input_ = features_model(image,return_tensors=\"tf\")['pixel_values'].numpy()[0]\n",
    "            #nimage = cv2.resize(input_,(64,64))\n",
    "            #nimage = input_.T\n",
    "            data.append(image)\n",
    "            if folder == 'comofod/morphed':\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d5f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "labels = to_categorical(labels,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68197845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)\n",
    "print(trainX.shape, testX.shape, trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf1d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "model = ResNet50(weights = 'imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "flat = Flatten()(model.layers[-2].output)\n",
    "output = Dense(2, activation='softmax')(flat)\n",
    "model = Model(model.input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs',write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c39fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H = model.fit(x=trainAug.flow(trainX, trainY, batch_size=8),steps_per_epoch=len(trainX) // 8, validation_data=valAug.flow(testX, testY),\n",
    "# validation_steps=len(testX) // 8,epochs=25,callbacks=[tensorboard])\n",
    "\n",
    "H = model.fit(trainX, trainY, batch_size=1, validation_data=(testX, testY),epochs=2,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('morph_cam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaced17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.evaluate(testX,testY, verbose=0)\n",
    "print(\"Test Loss is: \", acc[0])\n",
    "print(\"Test accuracy is: \", acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(testX)\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "y_test=np.argmax(testY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)   \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    plt.figure(figsize=(20,4))    \n",
    "    labels = [0,1]\n",
    "    cmap=sns.light_palette(\"blue\")    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a68b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = \"conv5_block3_3_conv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_PATH = 'test/casia2_morphed.jpg'\n",
    "LAYER_NAME = 'conv5_block3_add'\n",
    "\n",
    "image =cv2.imread(IMAGE_PATH)\n",
    "#input_ = features_model(image,return_tensors=\"tf\")['pixel_values'].numpy()[0]\n",
    "#nimage = input_.T\n",
    "img1 = np.array(cv2.resize(image, (128,128)),dtype=\"float32\") / 255.0\n",
    "img2 = np.expand_dims(img1,axis=0)\n",
    "#img2 = np.array(img2,dtype=\"float32\") / 255.0\n",
    "i = model.predict(img2)[0]\n",
    "print(i)\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(LAYER_NAME).output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(np.array([img1]))\n",
    "    loss = predictions[:,0]\n",
    "\n",
    "output = conv_outputs[0]\n",
    "grads = tape.gradient(loss, conv_outputs)[0]  * 1e+08\n",
    "gate_f = tf.cast(output > 0, 'float32')\n",
    "gate_r = tf.cast(grads > 0, 'float32')\n",
    "guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\n",
    "\n",
    "weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "cam = np.ones(output.shape[0: 2], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, :, i]\n",
    "\n",
    "cam = cv2.resize(cam.numpy(), (image.shape[1], image.shape[0]))\n",
    "denom = (cam.max() - cam.min()) + 1e-16\n",
    "cam = np.maximum(cam, 0)\n",
    "heatmap = (cam - cam.min()) / denom\n",
    "cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "print(image.shape, cam.shape)\n",
    "output_image = cv2.addWeighted(cv2.cvtColor(image.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n",
    "\n",
    "cv2.imwrite('7.png', output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f7f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
