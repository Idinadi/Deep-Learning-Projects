{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "model1 = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "data=[]\n",
    "labels = []\n",
    "\n",
    "random.seed(40)\n",
    "j = 0\n",
    "listing2 = os.listdir('dataset/normal')\n",
    "for vid2 in listing2:\n",
    "    vid2 = 'dataset/normal/'+vid2\n",
    "    label = vid2.split(\"/\")[1]\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid2)\n",
    "    i=0\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        count += 30\n",
    "        if frame is None:\n",
    "            break\n",
    "        frame=cv2.resize(frame,(128,128))  \n",
    "        x = np.expand_dims(frame,axis=0)\n",
    "        feature= model1.predict(x)\n",
    "        feature = np.reshape(feature,(32768))\n",
    "        print(feature.shape)\n",
    "        frames.append(feature)\n",
    "        labels.append(label)\n",
    "        if len(frames) > 4:\n",
    "            break\n",
    "        \n",
    "        cap.set(1, count)    \n",
    "\n",
    "    input=np.array(frames)\n",
    "    print(input.shape, label) \n",
    "    if input.shape == (5,32768):\n",
    "        data.append(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_1= np.array(data)\n",
    "print(X_tr_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "random.seed(40)\n",
    "j = 0\n",
    "listing2 = os.listdir('dataset/anomoly')\n",
    "for vid2 in listing2:\n",
    "    vid2 = 'dataset/anomoly/'+vid2\n",
    "    label = vid2.split(\"/\")[1]\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid2)\n",
    "    i=0\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        count += 30\n",
    "        if frame is None:\n",
    "            break\n",
    "        frame=cv2.resize(frame,(128,128))  \n",
    "        x = np.expand_dims(frame,axis=0)\n",
    "        feature= model1.predict(x)\n",
    "        feature = np.reshape(feature,(32768))\n",
    "        print(feature.shape)\n",
    "        frames.append(feature)\n",
    "        labels.append(label)\n",
    "        if len(frames) > 4:\n",
    "            break\n",
    "        \n",
    "        cap.set(1, count)    \n",
    "\n",
    "    input=np.array(frames)\n",
    "    print(input.shape, label) \n",
    "    if input.shape == (5,32768):\n",
    "        data.append(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_2= np.array(data)\n",
    "print(X_tr_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data and labels to NumPy arrays\n",
    "num_samples=X_tr_2.shape[0]\n",
    "\n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:239]= 0    \n",
    "label[240:493] = 1 \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "labels = np.array(label)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_tr_2, labels,test_size=0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape,testX.shape, trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, LSTM, Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras import Sequential\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64,activation='relu', input_shape=(5,32768)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "epochs = 500\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=1e-2, momentum=0.9, decay=1e-2 / epochs)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    " \n",
    "# train the head of the network for a few epochs (all other layers\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "# initialized with actual \"learned\" values versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(trainX, trainY, batch_size=128,\n",
    "                        validation_data=(testX, testY),  epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=['normal','anomaly']))\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"anomaly_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "model1 = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "model = load_model(\"anomaly_model\")\n",
    "\n",
    "#cap = cv2.VideoCapture(\"rtsp://admin:admin@123@192.168.1.125:554/\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    frames=[]\n",
    "    label = \"Normal\"\n",
    "    ret, frame1 = cap.read() \n",
    "    for i in range(0,5):\n",
    "        ret, frame = cap.read()\n",
    "        original = frame.copy()\n",
    "        if frame is None:\n",
    "            break\n",
    "        frame=cv2.resize(frame,(128, 128))\n",
    "        x = np.expand_dims(frame,axis=0)\n",
    "        feature= model1.predict(x)\n",
    "        feature = np.reshape(feature,(32768))\n",
    "        frames.append(feature)\n",
    "    frames = np.array(frames)\n",
    "    frames = np.expand_dims(frames,axis=0)\n",
    "    pred=model.predict(frames)[0]\n",
    "    if pred[1] > pred[0]:\n",
    "        label = \"Anomoly Detected!\"\n",
    "        cv2.putText(frame1,label,(20,20), cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,0,0), 3)\n",
    "    else:\n",
    "        label = \"Normal\"\n",
    "        cv2.putText(frame1,label,(20,20), cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,0,0), 3)\n",
    "    print(label)\n",
    "    cv2.imshow(\"output\", frame1)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
